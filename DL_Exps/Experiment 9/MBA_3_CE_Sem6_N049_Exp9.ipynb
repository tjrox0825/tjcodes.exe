{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MBA_3_CE_Sem6_N049_Exp9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5id8OHsXBrld"
      },
      "source": [
        "Name: Tarun Tanmay\n",
        "\n",
        "Class: MBATech CE\n",
        "\n",
        "Roll No: N049\n",
        "\n",
        "SAP ID: 70471018055"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSdAKSL4BmnW"
      },
      "source": [
        "#Experiment 9 \n",
        "#Use LSTM to predict stock price "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2u4Uj4FCsq4"
      },
      "source": [
        "LSTM stands for 'long short-term memory' in deep learning which is a recurrent neural netowk (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6e3jTo9DZ8i"
      },
      "source": [
        "Importing Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsNLzb5uBp2M"
      },
      "source": [
        "import numpy as np #numpy arrays for mathematical computations\n",
        "import matplotlib.pyplot as plt #for visualising the data in graphical form\n",
        "import pandas as pd #to read our csv file for preprocessing and further operations"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QEQf-MS1DYXR",
        "outputId": "a4ba7714-fd2a-45a2-a229-679f0a670cb2"
      },
      "source": [
        "dataset_train=pd.read_csv('NSE-TATAGLOBAL.csv') #reading the input data csv file\n",
        "dataset_train.head() #summarising what's in the input data csv file"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Last</th>\n",
              "      <th>Close</th>\n",
              "      <th>Total Trade Quantity</th>\n",
              "      <th>Turnover (Lacs)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-09-28</td>\n",
              "      <td>234.05</td>\n",
              "      <td>235.95</td>\n",
              "      <td>230.20</td>\n",
              "      <td>233.50</td>\n",
              "      <td>233.75</td>\n",
              "      <td>3069914</td>\n",
              "      <td>7162.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-09-27</td>\n",
              "      <td>234.55</td>\n",
              "      <td>236.80</td>\n",
              "      <td>231.10</td>\n",
              "      <td>233.80</td>\n",
              "      <td>233.25</td>\n",
              "      <td>5082859</td>\n",
              "      <td>11859.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-09-26</td>\n",
              "      <td>240.00</td>\n",
              "      <td>240.00</td>\n",
              "      <td>232.50</td>\n",
              "      <td>235.00</td>\n",
              "      <td>234.25</td>\n",
              "      <td>2240909</td>\n",
              "      <td>5248.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-09-25</td>\n",
              "      <td>233.30</td>\n",
              "      <td>236.75</td>\n",
              "      <td>232.00</td>\n",
              "      <td>236.25</td>\n",
              "      <td>236.10</td>\n",
              "      <td>2349368</td>\n",
              "      <td>5503.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-09-24</td>\n",
              "      <td>233.55</td>\n",
              "      <td>239.20</td>\n",
              "      <td>230.75</td>\n",
              "      <td>234.00</td>\n",
              "      <td>233.30</td>\n",
              "      <td>3423509</td>\n",
              "      <td>7999.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date    Open    High  ...   Close  Total Trade Quantity  Turnover (Lacs)\n",
              "0  2018-09-28  234.05  235.95  ...  233.75               3069914          7162.35\n",
              "1  2018-09-27  234.55  236.80  ...  233.25               5082859         11859.95\n",
              "2  2018-09-26  240.00  240.00  ...  234.25               2240909          5248.60\n",
              "3  2018-09-25  233.30  236.75  ...  236.10               2349368          5503.90\n",
              "4  2018-09-24  233.55  239.20  ...  233.30               3423509          7999.55\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLHlOa7hDxjL",
        "outputId": "9dd75938-0e29-4a11-e4f5-5436da19c765"
      },
      "source": [
        "dataset_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2035, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op4IcqG2D4Of"
      },
      "source": [
        "2035 rows and 8 columns, data given for each (7) days. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HAiDpDFoD9RK",
        "outputId": "1ef2594a-5659-4d4b-fcbb-72051d460d33"
      },
      "source": [
        "training_set=dataset_train.iloc[:,1:2] #we take only the first column which is open, and select all the rows\n",
        "training_set.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>234.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>234.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>240.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>233.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>233.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Open\n",
              "0  234.05\n",
              "1  234.55\n",
              "2  240.00\n",
              "3  233.30\n",
              "4  233.55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vcFd7trEixL",
        "outputId": "84afce59-af93-4f64-be95-433c418e753f"
      },
      "source": [
        "training_set.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2035, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkzzJCk8EllT"
      },
      "source": [
        "Now we have taken all the rows and only one column from our input dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot982HBeEqww"
      },
      "source": [
        "Converting training_set values into numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSNFaqM0EqZC"
      },
      "source": [
        "training_set=training_set.values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpVwdiCrE8dH"
      },
      "source": [
        "to get optimal results, we normalise all the values first"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yR6CSEYFC1J"
      },
      "source": [
        "PREPROCESSING:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ22AjRpE76A"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler #Transform features by scaling each feature in a range of 0 and 1\n",
        "scale=MinMaxScaler(feature_range=(0,1)) #we normalize the values, so that value is in range 0 to 1\n",
        "training_set_scaled= scale.fit_transform(training_set) #MinMax Regularization"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91Rn_Vs8GCZu",
        "outputId": "561e2b04-3b9d-4843-de4a-39da4e20108d"
      },
      "source": [
        "training_set_scaled.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2035, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMOzSf14GIX-"
      },
      "source": [
        "The shape is still the same, column shows the stock price of 2035 rows of each day"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S29X4G0KGFzC",
        "outputId": "30ce8f16-16da-4db5-d0fd-b7e643df0065"
      },
      "source": [
        "training_set_scaled[10] #opening value of the stock on the 11th day"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.54845904])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3eN-5PiGjxH"
      },
      "source": [
        "#iniitialising matrix X-train and y_train\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "for i in range(60,2035):\n",
        "  X_train.append(training_set_scaled[i-60:i,0]) # for i =60, rows from 0 to 59 will be appended as columns to X_train\n",
        "  y_train.append(training_set_scaled[i,0]) # for i=60, rows from 60 to 2034 will append in y_train\n",
        "X_train,y_train=np.array(X_train), np.array(y_train)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWBQCz2FJEOO",
        "outputId": "34e2f028-c82f-470d-b484-9fabc0af9539"
      },
      "source": [
        "X_train.shape #2035 -60 = 1975, i.e. first 60 rows are not appended in X_train but all other rows with 60 columns are appended"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1975, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xKMxNwEJFxf",
        "outputId": "216a6889-2bc0-4e30-a919-6587e999d149"
      },
      "source": [
        "y_train.shape #no column suggests that it is a vector not a matrix"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1975,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yMsy0OEJ1D2"
      },
      "source": [
        "X_train = np.reshape(X_train,(X_train.shape[0], X_train.shape[1], 1)) #we reshape the X_train with one additional dimension"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMpvy5NkJHkd",
        "outputId": "db01a9dd-2dd4-47d6-f9b3-ffdd80d8d2cd"
      },
      "source": [
        "X_train.shape # now we have one more dimension"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1975, 60, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V93PB7GDK3uw"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense #fully connected layer to the neural network\n",
        "from keras.layers import LSTM #\n",
        "from keras.layers import Dropout #to avoid overfitting, we use the dropout layer in our neural networks"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIqgWAoEL6d-"
      },
      "source": [
        "BUILDING THE MODEL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ5zP6CHL5uf"
      },
      "source": [
        "model=Sequential() #adding layers to our neural network model one by one\n",
        "\n",
        "#First Hidden layer consists of 50 LSTM neurons\n",
        "#1 Layer:\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1))) #input layer will be LSTM which will use first column and the dimension of the training data\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#2 Layer\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#3 Layer\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#4 Layer/ Output Layer\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units=1)) #output is 1, since we are trying to predict stock value of one day"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-qrwkIxOQ1R"
      },
      "source": [
        "COMPILING THE MODEL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cRf8hzgOPLH"
      },
      "source": [
        "model.compile(optimizer='adam', loss=\"mean_squared_error\") #we use mean_squred_error to calculate the loss \n",
        "#adam optimizer will handle sparse gradient "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9Gr5694Oytj"
      },
      "source": [
        "FITTING THE MODEL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTCVFUzKO1a-",
        "outputId": "31ad81b3-d6fb-41c7-c116-edef19b8d896"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=150, batch_size=32) # fitting the model, training it with 150 epochs"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "62/62 [==============================] - 13s 103ms/step - loss: 0.0286\n",
            "Epoch 2/150\n",
            "62/62 [==============================] - 6s 102ms/step - loss: 0.0031\n",
            "Epoch 3/150\n",
            "62/62 [==============================] - 6s 103ms/step - loss: 0.0031\n",
            "Epoch 4/150\n",
            "62/62 [==============================] - 6s 102ms/step - loss: 0.0027\n",
            "Epoch 5/150\n",
            "62/62 [==============================] - 7s 105ms/step - loss: 0.0029\n",
            "Epoch 6/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 0.0024\n",
            "Epoch 7/150\n",
            "62/62 [==============================] - 6s 105ms/step - loss: 0.0021\n",
            "Epoch 8/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 0.0021\n",
            "Epoch 9/150\n",
            "62/62 [==============================] - 7s 105ms/step - loss: 0.0019\n",
            "Epoch 10/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 0.0025\n",
            "Epoch 11/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 0.0022\n",
            "Epoch 12/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 0.0017\n",
            "Epoch 13/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 0.0020\n",
            "Epoch 14/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0021\n",
            "Epoch 15/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0015\n",
            "Epoch 16/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0015\n",
            "Epoch 17/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 0.0016\n",
            "Epoch 18/150\n",
            "62/62 [==============================] - 7s 105ms/step - loss: 0.0017\n",
            "Epoch 19/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 0.0016\n",
            "Epoch 20/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 0.0016\n",
            "Epoch 21/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0015\n",
            "Epoch 22/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0015\n",
            "Epoch 23/150\n",
            "62/62 [==============================] - 7s 109ms/step - loss: 0.0016\n",
            "Epoch 24/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 0.0015\n",
            "Epoch 25/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 0.0014\n",
            "Epoch 26/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 0.0014\n",
            "Epoch 27/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 0.0016\n",
            "Epoch 28/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0019\n",
            "Epoch 29/150\n",
            "62/62 [==============================] - 7s 109ms/step - loss: 0.0017\n",
            "Epoch 30/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 0.0012\n",
            "Epoch 31/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 0.0013\n",
            "Epoch 32/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0013\n",
            "Epoch 33/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0012\n",
            "Epoch 34/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0010\n",
            "Epoch 35/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 9.9740e-04\n",
            "Epoch 36/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 0.0011\n",
            "Epoch 37/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 0.0011\n",
            "Epoch 38/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0011\n",
            "Epoch 39/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0010\n",
            "Epoch 40/150\n",
            "62/62 [==============================] - 7s 109ms/step - loss: 0.0010\n",
            "Epoch 41/150\n",
            "62/62 [==============================] - 7s 114ms/step - loss: 9.9816e-04\n",
            "Epoch 42/150\n",
            "62/62 [==============================] - 8s 123ms/step - loss: 9.9368e-04\n",
            "Epoch 43/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 9.8046e-04\n",
            "Epoch 44/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0011\n",
            "Epoch 45/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 8.1730e-04\n",
            "Epoch 46/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 0.0011\n",
            "Epoch 47/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0010\n",
            "Epoch 48/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0010\n",
            "Epoch 49/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 7.8339e-04\n",
            "Epoch 50/150\n",
            "62/62 [==============================] - 7s 109ms/step - loss: 0.0011\n",
            "Epoch 51/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 9.9118e-04\n",
            "Epoch 52/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 8.5422e-04\n",
            "Epoch 53/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 8.9537e-04\n",
            "Epoch 54/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.7167e-04\n",
            "Epoch 55/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 8.7156e-04\n",
            "Epoch 56/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 9.5567e-04\n",
            "Epoch 57/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.7805e-04\n",
            "Epoch 58/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 8.8036e-04\n",
            "Epoch 59/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 8.4485e-04\n",
            "Epoch 60/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 9.2739e-04\n",
            "Epoch 61/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.6772e-04\n",
            "Epoch 62/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 7.9462e-04\n",
            "Epoch 63/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.7790e-04\n",
            "Epoch 64/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 0.0010\n",
            "Epoch 65/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 7.7881e-04\n",
            "Epoch 66/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 7.8288e-04\n",
            "Epoch 67/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 9.3848e-04\n",
            "Epoch 68/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 8.0238e-04\n",
            "Epoch 69/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 8.1360e-04\n",
            "Epoch 70/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 0.0010\n",
            "Epoch 71/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 7.4430e-04\n",
            "Epoch 72/150\n",
            "62/62 [==============================] - 7s 105ms/step - loss: 7.6628e-04\n",
            "Epoch 73/150\n",
            "62/62 [==============================] - 7s 105ms/step - loss: 8.6437e-04\n",
            "Epoch 74/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.6607e-04\n",
            "Epoch 75/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 8.2354e-04\n",
            "Epoch 76/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 7.0704e-04\n",
            "Epoch 77/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 8.2456e-04\n",
            "Epoch 78/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 6.5271e-04\n",
            "Epoch 79/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 5.8699e-04\n",
            "Epoch 80/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.7280e-04\n",
            "Epoch 81/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.9240e-04\n",
            "Epoch 82/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.0727e-04\n",
            "Epoch 83/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.7091e-04\n",
            "Epoch 84/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 9.3221e-04\n",
            "Epoch 85/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 6.8761e-04\n",
            "Epoch 86/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.0139e-04\n",
            "Epoch 87/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.5117e-04\n",
            "Epoch 88/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.3301e-04\n",
            "Epoch 89/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 7.3193e-04\n",
            "Epoch 90/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 7.4713e-04\n",
            "Epoch 91/150\n",
            "62/62 [==============================] - 7s 105ms/step - loss: 8.1118e-04\n",
            "Epoch 92/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 6.3065e-04\n",
            "Epoch 93/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 9.1737e-04\n",
            "Epoch 94/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 7.6149e-04\n",
            "Epoch 95/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.7583e-04\n",
            "Epoch 96/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 7.0747e-04\n",
            "Epoch 97/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 6.7283e-04\n",
            "Epoch 98/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 7.8816e-04\n",
            "Epoch 99/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.1270e-04\n",
            "Epoch 100/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.1653e-04\n",
            "Epoch 101/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 8.2203e-04\n",
            "Epoch 102/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 5.8431e-04\n",
            "Epoch 103/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 6.4470e-04\n",
            "Epoch 104/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.2346e-04\n",
            "Epoch 105/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 6.8499e-04\n",
            "Epoch 106/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.3572e-04\n",
            "Epoch 107/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.6830e-04\n",
            "Epoch 108/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 6.6839e-04\n",
            "Epoch 109/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.5072e-04\n",
            "Epoch 110/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 6.7144e-04\n",
            "Epoch 111/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 6.1604e-04\n",
            "Epoch 112/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 6.0746e-04\n",
            "Epoch 113/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 7.6479e-04\n",
            "Epoch 114/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.6314e-04\n",
            "Epoch 115/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.4306e-04\n",
            "Epoch 116/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 5.7719e-04\n",
            "Epoch 117/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.8334e-04\n",
            "Epoch 118/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 5.7441e-04\n",
            "Epoch 119/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 5.9341e-04\n",
            "Epoch 120/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.7147e-04\n",
            "Epoch 121/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 7.1403e-04\n",
            "Epoch 122/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 7.5054e-04\n",
            "Epoch 123/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 7.1714e-04\n",
            "Epoch 124/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 6.0862e-04\n",
            "Epoch 125/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 6.2236e-04\n",
            "Epoch 126/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.8451e-04\n",
            "Epoch 127/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 6.1008e-04\n",
            "Epoch 128/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 5.2075e-04\n",
            "Epoch 129/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.1249e-04\n",
            "Epoch 130/150\n",
            "62/62 [==============================] - 7s 109ms/step - loss: 5.1797e-04\n",
            "Epoch 131/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.3500e-04\n",
            "Epoch 132/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 6.5958e-04\n",
            "Epoch 133/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.4578e-04\n",
            "Epoch 134/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 5.8043e-04\n",
            "Epoch 135/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.8500e-04\n",
            "Epoch 136/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 6.6813e-04\n",
            "Epoch 137/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.3075e-04\n",
            "Epoch 138/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 5.7956e-04\n",
            "Epoch 139/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 5.8980e-04\n",
            "Epoch 140/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 5.5038e-04\n",
            "Epoch 141/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 7.3794e-04\n",
            "Epoch 142/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 5.2422e-04\n",
            "Epoch 143/150\n",
            "62/62 [==============================] - 7s 106ms/step - loss: 7.7568e-04\n",
            "Epoch 144/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.2101e-04\n",
            "Epoch 145/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 5.2212e-04\n",
            "Epoch 146/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 6.4941e-04\n",
            "Epoch 147/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 6.1679e-04\n",
            "Epoch 148/150\n",
            "62/62 [==============================] - 7s 107ms/step - loss: 5.7327e-04\n",
            "Epoch 149/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 5.7250e-04\n",
            "Epoch 150/150\n",
            "62/62 [==============================] - 7s 108ms/step - loss: 6.3782e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f76d08d5810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "foLbADj4PcmC",
        "outputId": "76073b60-4857-42a9-9935-06aa7707a2ab"
      },
      "source": [
        "dataset_test=pd.read_csv('tatatest.csv')\n",
        "dataset_test.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Last</th>\n",
              "      <th>Close</th>\n",
              "      <th>Total Trade Quantity</th>\n",
              "      <th>Turnover (Lacs)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-10-24</td>\n",
              "      <td>220.10</td>\n",
              "      <td>221.25</td>\n",
              "      <td>217.05</td>\n",
              "      <td>219.55</td>\n",
              "      <td>219.80</td>\n",
              "      <td>2171956</td>\n",
              "      <td>4771.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-10-23</td>\n",
              "      <td>221.10</td>\n",
              "      <td>222.20</td>\n",
              "      <td>214.75</td>\n",
              "      <td>219.55</td>\n",
              "      <td>218.30</td>\n",
              "      <td>1416279</td>\n",
              "      <td>3092.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-10-22</td>\n",
              "      <td>229.45</td>\n",
              "      <td>231.60</td>\n",
              "      <td>222.00</td>\n",
              "      <td>223.05</td>\n",
              "      <td>223.25</td>\n",
              "      <td>3529711</td>\n",
              "      <td>8028.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-10-19</td>\n",
              "      <td>230.30</td>\n",
              "      <td>232.70</td>\n",
              "      <td>225.50</td>\n",
              "      <td>227.75</td>\n",
              "      <td>227.20</td>\n",
              "      <td>1527904</td>\n",
              "      <td>3490.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-10-17</td>\n",
              "      <td>237.70</td>\n",
              "      <td>240.80</td>\n",
              "      <td>229.45</td>\n",
              "      <td>231.30</td>\n",
              "      <td>231.10</td>\n",
              "      <td>2945914</td>\n",
              "      <td>6961.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date    Open    High  ...   Close  Total Trade Quantity  Turnover (Lacs)\n",
              "0  2018-10-24  220.10  221.25  ...  219.80               2171956          4771.34\n",
              "1  2018-10-23  221.10  222.20  ...  218.30               1416279          3092.15\n",
              "2  2018-10-22  229.45  231.60  ...  223.25               3529711          8028.37\n",
              "3  2018-10-19  230.30  232.70  ...  227.20               1527904          3490.78\n",
              "4  2018-10-17  237.70  240.80  ...  231.10               2945914          6961.65\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbka4uNNQBfo",
        "outputId": "73c3b3f7-9795-44f4-a490-fde4007619c7"
      },
      "source": [
        "dataset_test.shape #16 rows and 8 columns in test dataset"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AuRnyi4QN1p"
      },
      "source": [
        "stock_price = dataset_test.iloc[:,1:2].values"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJowKbPKQtX7",
        "outputId": "c393df1b-f6a8-4a42-e266-71673f01419a"
      },
      "source": [
        "stock_price.shape #we take all the rows and only 1 column"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DA2Z-RgQ1k2",
        "outputId": "3138f920-e0bc-418e-ebcf-0846411a4a71"
      },
      "source": [
        "test_total=pd.concat((dataset_train['Open'],dataset_test['Open']),axis=0) #2035 rows from training dataset, and 16 rows from testing dataset is concatenated\n",
        "test_total.shape #2035+16 = 2051 rows in total"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2051,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE8QvHhMRlrW",
        "outputId": "741936a3-5088-438d-a41a-c88b2494678d"
      },
      "source": [
        "input_samples=test_total[len(dataset_train)-60:].values #last 60 values are taken now \n",
        "input_samples.shape #last 60 values are from training dataset, and 16 values from testing dataset"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Cg6QVPXR9PX"
      },
      "source": [
        "60 + 16 = 76 rows in total"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwa-sFBISAGU",
        "outputId": "2e8eabbf-1230-429a-a554-eb8167c60d8e"
      },
      "source": [
        "input_samples = input_samples.reshape(-1,1) #reshaping the input_samples\n",
        "input_samples.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmKf0mrcUMz-"
      },
      "source": [
        "input_samples=scale.transform(input_samples) "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nnpctg6EUjnu"
      },
      "source": [
        "X_test=[]\n",
        "for i in range(60,76):\n",
        "  X_test.append(input_samples[i-60:i,0]) #for i =60, 0 to 75 rows are appended in X_test\n",
        "X_test=np.array(X_test)\n",
        "X_test=np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD6tfomUVz8s"
      },
      "source": [
        "pred_stock_price=model.predict(X_test)\n",
        "pred_stock_price=scale.inverse_transform(pred_stock_price) #predicting the stock prices"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "NbG-njDhWbc1",
        "outputId": "ca9778c3-21a4-4889-8d7d-ad01354b104f"
      },
      "source": [
        "#setting green and red color respectively for predicted and test stock price\n",
        "plt.plot(dataset_test['Open'],color='red', label='test')\n",
        "plt.plot(pred_stock_price, color='green', label='predicted stock price') \n",
        "#setting labels for plotting graph\n",
        "plt.title('Stock price prediction')\n",
        "plt.xlabel('days')\n",
        "plt.ylabel('Stcok price')\n",
        "plt.legend()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f76cc9abc10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7p5syhKXqba"
      },
      "source": [
        "CONCLUSION: \n",
        "\n",
        "1) The Graph shows that the foirst few days that the differnevce beetewwn the ios lagrge, this differnece reduce after the number of days are increased.  \n",
        "\n",
        "2) Differnece can be reuduced by increasing the number of epochs."
      ]
    }
  ]
}
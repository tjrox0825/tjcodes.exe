{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MBA_3_CE_Sem6_N049_Exp3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh6m6MgfmaFD"
      },
      "source": [
        "Name: Tarun Tanmay\n",
        "\n",
        "Class: MBATech CE\n",
        "\n",
        "Sem: 6\n",
        "\n",
        "Roll No: N049"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eIic4OGl0XR"
      },
      "source": [
        "#Experiment 3 \n",
        "#ANN with Multiple Layers for classification "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WEo0U4lnKhN"
      },
      "source": [
        "Importing required libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-4PV_7rmYm6"
      },
      "source": [
        "from numpy import loadtxt #loading data from a text file or a csv file \n",
        "from keras.models import Sequential #(used to build the ann model with sequential layers)\n",
        "from keras.layers import Dense #(used for entering parameters for each layer)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FukTsupJospQ"
      },
      "source": [
        "Importing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQow7o4uoZgT",
        "outputId": "4a783f92-1111-422e-ae96-680470ec02ea"
      },
      "source": [
        "dataset=loadtxt('pima-indians-diabetes.csv', delimiter=',') #importing the dataset text, separated with ,\n",
        "dataset\n",
        "#dataset.shape #(768rows and 9 columns)\n",
        "#dataset[0,:]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3eM5GRup7Pe"
      },
      "source": [
        "Explanation of Dataset:\n",
        "\n",
        "column1: number of times person has undrgone surgery\n",
        "\n",
        "column2: glucose concentration\n",
        "\n",
        "column3: blood pressure \n",
        "\n",
        "column4: skinfold thickness\n",
        "\n",
        "column5: serum insulin\n",
        "\n",
        "column6: Body Mass Index (BMI)\n",
        "\n",
        "coliumn7: medical parameter \n",
        "\n",
        "column8: age\n",
        "\n",
        "column9: person has diabetes (1) or not (0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niWyw7r2qS1D"
      },
      "source": [
        "X=dataset[:,0:8] #all rows and columns from 1 to 8\n",
        "y=dataset[:,8] #all rows and only 8th column"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAXfLperrZxB"
      },
      "source": [
        "Training and Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw5fAbRmqrVZ",
        "outputId": "3caedf1d-042a-43a1-84c4-98f932f97206"
      },
      "source": [
        "from sklearn.model_selection import train_test_split #randomly splitting the dataset for training and testing the model\n",
        "train_x,test_x,train_y,test_y=train_test_split(X,y,test_size=0.2, random_state=4) #test size is given as 20%, random_state is kept same for same answer\n",
        "test_x.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1T2P6D4r0FV"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(12,input_dim=8, activation='relu')) #relu function is used as the activation function \n",
        "#8 attributes, one per each sample (column)\n",
        "#12 neurons are there in the next hidden layer, after input layer having 8 neurons\n",
        "model.add(Dense(8,activation='relu')) \n",
        "model.add(Dense(1,activation='sigmoid')) #classifier: logic 1 or logic 0\n",
        "#In last layer only 1 neuron is present and thus binary classifier is used "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awDH0m1Uu0_R"
      },
      "source": [
        "Compiling the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYt0UbJHut1n"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "#{(probability of actual class) * (log of probability of predicted class)}\n",
        "#loss=act*log(pred)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HowjAtLyDnG",
        "outputId": "0db97793-c08c-4302-d4c3-45b719162335"
      },
      "source": [
        "model.fit(train_x,train_y,epochs=150,batch_size=20) \n",
        "#after claclulating loss, we backpropogate and see the gradient \n",
        "#after weights are changed, input is given again and output is claculated again"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7638\n",
            "Epoch 2/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7638\n",
            "Epoch 3/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7720\n",
            "Epoch 4/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7704\n",
            "Epoch 5/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7687\n",
            "Epoch 6/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7704\n",
            "Epoch 7/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7557\n",
            "Epoch 8/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7671\n",
            "Epoch 9/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7590\n",
            "Epoch 10/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7590\n",
            "Epoch 11/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7785\n",
            "Epoch 12/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7785\n",
            "Epoch 13/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7655\n",
            "Epoch 14/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7785\n",
            "Epoch 15/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7752\n",
            "Epoch 16/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7736\n",
            "Epoch 17/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7834\n",
            "Epoch 18/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7622\n",
            "Epoch 19/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.7818\n",
            "Epoch 20/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7524\n",
            "Epoch 21/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7736\n",
            "Epoch 22/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7638\n",
            "Epoch 23/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7687\n",
            "Epoch 24/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7590\n",
            "Epoch 25/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7818\n",
            "Epoch 26/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7671\n",
            "Epoch 27/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7671\n",
            "Epoch 28/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7736\n",
            "Epoch 29/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7704\n",
            "Epoch 30/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7704\n",
            "Epoch 31/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7801\n",
            "Epoch 32/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7801\n",
            "Epoch 33/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7720\n",
            "Epoch 34/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7622\n",
            "Epoch 35/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7736\n",
            "Epoch 36/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7671\n",
            "Epoch 37/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.7769\n",
            "Epoch 38/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7687\n",
            "Epoch 39/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7769\n",
            "Epoch 40/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7752\n",
            "Epoch 41/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7769\n",
            "Epoch 42/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7736\n",
            "Epoch 43/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7638\n",
            "Epoch 44/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7785\n",
            "Epoch 45/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7769\n",
            "Epoch 46/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7638\n",
            "Epoch 47/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7899\n",
            "Epoch 48/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7345\n",
            "Epoch 49/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7671\n",
            "Epoch 50/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7883\n",
            "Epoch 51/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7590\n",
            "Epoch 52/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.7720\n",
            "Epoch 53/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.7850\n",
            "Epoch 54/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7736\n",
            "Epoch 55/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7704\n",
            "Epoch 56/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7655\n",
            "Epoch 57/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7850\n",
            "Epoch 58/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7687\n",
            "Epoch 59/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7818\n",
            "Epoch 60/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7704\n",
            "Epoch 61/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7850\n",
            "Epoch 62/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7736\n",
            "Epoch 63/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7801\n",
            "Epoch 64/150\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7736\n",
            "Epoch 65/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7785\n",
            "Epoch 66/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7801\n",
            "Epoch 67/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7752\n",
            "Epoch 68/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7720\n",
            "Epoch 69/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7801\n",
            "Epoch 70/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7883\n",
            "Epoch 71/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7769\n",
            "Epoch 72/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7769\n",
            "Epoch 73/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7622\n",
            "Epoch 74/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7769\n",
            "Epoch 75/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.7671\n",
            "Epoch 76/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7622\n",
            "Epoch 77/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7834\n",
            "Epoch 78/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7752\n",
            "Epoch 79/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7736\n",
            "Epoch 80/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.7883\n",
            "Epoch 81/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7785\n",
            "Epoch 82/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7866\n",
            "Epoch 83/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7883\n",
            "Epoch 84/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7769\n",
            "Epoch 85/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7948\n",
            "Epoch 86/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7785\n",
            "Epoch 87/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7785\n",
            "Epoch 88/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7687\n",
            "Epoch 89/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.7655\n",
            "Epoch 90/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7638\n",
            "Epoch 91/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7736\n",
            "Epoch 92/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7638\n",
            "Epoch 93/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7720\n",
            "Epoch 94/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7720\n",
            "Epoch 95/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7818\n",
            "Epoch 96/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7736\n",
            "Epoch 97/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7883\n",
            "Epoch 98/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7655\n",
            "Epoch 99/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7899\n",
            "Epoch 100/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7866\n",
            "Epoch 101/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7801\n",
            "Epoch 102/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7785\n",
            "Epoch 103/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7915\n",
            "Epoch 104/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7769\n",
            "Epoch 105/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7834\n",
            "Epoch 106/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7932\n",
            "Epoch 107/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7818\n",
            "Epoch 108/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7866\n",
            "Epoch 109/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7785\n",
            "Epoch 110/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7671\n",
            "Epoch 111/150\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7769\n",
            "Epoch 112/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7801\n",
            "Epoch 113/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7769\n",
            "Epoch 114/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.7769\n",
            "Epoch 115/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7850\n",
            "Epoch 116/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7638\n",
            "Epoch 117/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7866\n",
            "Epoch 118/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7720\n",
            "Epoch 119/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7850\n",
            "Epoch 120/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7638\n",
            "Epoch 121/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7801\n",
            "Epoch 122/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7752\n",
            "Epoch 123/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7769\n",
            "Epoch 124/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7818\n",
            "Epoch 125/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7834\n",
            "Epoch 126/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.7866\n",
            "Epoch 127/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7752\n",
            "Epoch 128/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7769\n",
            "Epoch 129/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7704\n",
            "Epoch 130/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.7655\n",
            "Epoch 131/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7964\n",
            "Epoch 132/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7606\n",
            "Epoch 133/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7590\n",
            "Epoch 134/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7801\n",
            "Epoch 135/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7671\n",
            "Epoch 136/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7687\n",
            "Epoch 137/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7850\n",
            "Epoch 138/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7752\n",
            "Epoch 139/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7818\n",
            "Epoch 140/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7704\n",
            "Epoch 141/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7736\n",
            "Epoch 142/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7638\n",
            "Epoch 143/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7736\n",
            "Epoch 144/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7850\n",
            "Epoch 145/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7818\n",
            "Epoch 146/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7866\n",
            "Epoch 147/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7866\n",
            "Epoch 148/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7801\n",
            "Epoch 149/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7801\n",
            "Epoch 150/150\n",
            "31/31 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe7d70c71d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHbXaFZp0txK",
        "outputId": "2a935453-3b34-4060-dbb9-5b396d1f3e52"
      },
      "source": [
        "training_accuracy=model.evaluate(train_x,train_y)\n",
        "print(\"%s:%.2f%%\" % (model.metrics_names[0], training_accuracy[0]*100))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 952us/step - loss: 0.4364 - accuracy: 0.7866\n",
            "loss:43.64%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px84rmzi2sJA",
        "outputId": "057e11d3-1668-43d6-d2d2-8654133ffaab"
      },
      "source": [
        "training_accuracy"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4363956153392792, 0.7866449356079102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BihKVMp2wDT",
        "outputId": "173834ed-90b9-4977-bbfc-9da02e0b3e3f"
      },
      "source": [
        "test_accuracy=model.evaluate(test_x,test_y)\n",
        "print(\"%s:%.2f%%\" % (model.metrics_names[1], test_accuracy[1]*100))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7727\n",
            "accuracy:77.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujs7jp3039mJ"
      },
      "source": [
        "We got almost the same accuracy for both training and testing set, so model is correct.\n",
        "\n",
        "If network was not trained well, then high bias\n",
        "\n",
        "If network was not tested well, then high variance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByZMTCqy4JmF",
        "outputId": "587aefe4-7967-42c8-d334-ff6cbeb5eb21"
      },
      "source": [
        "predict=model.predict_classes(test_x)\n",
        "for i in range(10):\n",
        "  print('%s ==> %d (expected %d)' % (test_x[i].tolist(), predict[i],test_y[i]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 100.0, 66.0, 29.0, 196.0, 32.0, 0.444, 42.0] ==> 0 (expected 0)\n",
            "[9.0, 57.0, 80.0, 37.0, 0.0, 32.8, 0.096, 41.0] ==> 0 (expected 0)\n",
            "[0.0, 100.0, 70.0, 26.0, 50.0, 30.8, 0.597, 21.0] ==> 0 (expected 0)\n",
            "[1.0, 119.0, 88.0, 41.0, 170.0, 45.3, 0.507, 26.0] ==> 0 (expected 0)\n",
            "[2.0, 102.0, 86.0, 36.0, 120.0, 45.5, 0.127, 23.0] ==> 0 (expected 1)\n",
            "[13.0, 126.0, 90.0, 0.0, 0.0, 43.4, 0.583, 42.0] ==> 1 (expected 1)\n",
            "[3.0, 171.0, 72.0, 33.0, 135.0, 33.3, 0.199, 24.0] ==> 0 (expected 1)\n",
            "[12.0, 92.0, 62.0, 7.0, 258.0, 27.6, 0.926, 44.0] ==> 1 (expected 1)\n",
            "[12.0, 151.0, 70.0, 40.0, 271.0, 41.8, 0.742, 38.0] ==> 1 (expected 1)\n",
            "[11.0, 85.0, 74.0, 0.0, 0.0, 30.1, 0.3, 35.0] ==> 0 (expected 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK9PGDm8442l"
      },
      "source": [
        "First ten samples are taken, and predicted and actual data is compared"
      ]
    }
  ]
}